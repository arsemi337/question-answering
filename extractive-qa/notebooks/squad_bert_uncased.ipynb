{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:55:32.667104500Z",
     "start_time": "2023-10-30T16:55:28.974930100Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForQuestionAnswering,\n",
    "    DefaultDataCollator,\n",
    "    keras_callbacks,\n",
    ")\n",
    "import tensorflow as tf\n",
    "from huggingface_hub import notebook_login\n",
    "from question_answering.constants import constants\n",
    "from question_answering.utils import core_qa_utils, extractive_qa_utils\n",
    "from question_answering.paths import extractive_qa_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b7529904f21909",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:55:33.767177200Z",
     "start_time": "2023-10-30T16:55:32.671101800Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train, df_val, df_test = core_qa_utils.load_train_val_test_datasets(\n",
    "    extractive_qa_paths.squad_dataset_dir\n",
    ")\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = core_qa_utils.convert_dataframes_to_datasets(\n",
    "    [df_train, df_val, df_test]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db291e0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:55:34.310328600Z",
     "start_time": "2023-10-30T16:55:33.761176600Z"
    }
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d177b07",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:56:26.168622800Z",
     "start_time": "2023-10-30T16:55:34.313329300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/68716 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ddf35b2c89b4fa8b3501da7ee35bebe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (520 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/14724 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d833c9bc140c49d892ab2af248aca06c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/14725 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "63987fb89d78493e86d4887d9effc016"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of tokens in tokenized train dataset:  870\n",
      "Max number of tokens in tokenized val dataset:  866\n",
      "Max number of tokens in tokenized test dataset:  817\n"
     ]
    }
   ],
   "source": [
    "def tokenize_sample(sample, max_tokens=None, padding=False):\n",
    "    question = sample[\"question\"].strip()\n",
    "    context = sample[\"context\"].strip()\n",
    "\n",
    "    return tokenizer(question, context, max_length=max_tokens, padding=padding)\n",
    "\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_sample)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_sample)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_sample)\n",
    "\n",
    "print(\n",
    "    \"Max number of tokens in tokenized train dataset: \",\n",
    "    len(max(tokenized_train_dataset[\"input_ids\"], key=len)),\n",
    ")\n",
    "print(\n",
    "    \"Max number of tokens in tokenized val dataset: \",\n",
    "    len(max(tokenized_val_dataset[\"input_ids\"], key=len)),\n",
    ")\n",
    "print(\n",
    "    \"Max number of tokens in tokenized test dataset: \",\n",
    "    len(max(tokenized_test_dataset[\"input_ids\"], key=len)),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10e53325b1b3a28b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:03.091160600Z",
     "start_time": "2023-10-30T16:56:26.167624100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'indices'=<generator object filter_samples_below_number_of_tokens.<locals>.<genexpr> at 0x00000197D867F610> of the transform datasets.arrow_dataset.Dataset.select couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    }
   ],
   "source": [
    "max_length = 384\n",
    "\n",
    "\n",
    "def filter_samples_below_number_of_tokens(dataset, max_tokens: int):\n",
    "    indices_to_remove = []\n",
    "\n",
    "    # Find indices of samples where number of tokens exceeds max number of tokens\n",
    "    for index, sample in enumerate(dataset):\n",
    "        tokenized_sample = tokenize_sample(sample)\n",
    "        if len(tokenized_sample[\"input_ids\"]) > max_tokens:\n",
    "            indices_to_remove.append(index)\n",
    "\n",
    "    # Keep only samples with number of tokens less or equal than max number of tokens\n",
    "    dataset_indices = range(len(dataset))\n",
    "    filtered_dataset = dataset.select(\n",
    "        index for index in dataset_indices if index not in set(indices_to_remove)\n",
    "    )\n",
    "\n",
    "    return filtered_dataset\n",
    "\n",
    "\n",
    "filtered_train_dataset = filter_samples_below_number_of_tokens(\n",
    "    train_dataset, max_tokens=max_length\n",
    ")\n",
    "filtered_val_dataset = filter_samples_below_number_of_tokens(\n",
    "    val_dataset, max_tokens=max_length\n",
    ")\n",
    "filtered_test_dataset = filter_samples_below_number_of_tokens(\n",
    "    test_dataset, max_tokens=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1aebcb2",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:03.108191900Z",
     "start_time": "2023-10-30T16:57:03.093160900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in tokenized train dataset before filtering:  68716\n",
      "Number of samples in tokenized val dataset before filtering:  14724\n",
      "Number of samples in tokenized test dataset before filtering:  14725\n",
      "\n",
      "---------------\n",
      "\n",
      "Number of samples in tokenized train dataset after filtering:  67964\n",
      "Number of samples in tokenized val dataset after filtering:  14573\n",
      "Number of samples in tokenized test dataset after filtering:  14552\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Number of samples in tokenized train dataset before filtering: \",\n",
    "    len(train_dataset),\n",
    ")\n",
    "print(\"Number of samples in tokenized val dataset before filtering: \", len(val_dataset))\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset before filtering: \", len(test_dataset)\n",
    ")\n",
    "\n",
    "print(\"\\n---------------\\n\")\n",
    "\n",
    "print(\n",
    "    \"Number of samples in tokenized train dataset after filtering: \",\n",
    "    len(filtered_train_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized val dataset after filtering: \",\n",
    "    len(filtered_val_dataset),\n",
    ")\n",
    "print(\n",
    "    \"Number of samples in tokenized test dataset after filtering: \",\n",
    "    len(filtered_test_dataset),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6cdd06c7a27f8c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:03.154193300Z",
     "start_time": "2023-10-30T16:57:03.109193100Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    questions = [q.strip() for q in dataset[\"question\"]]\n",
    "    contexts = [c.strip() for c in dataset[\"context\"]]\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        max_length=max_length,\n",
    "        padding=\"max_length\",\n",
    "        return_offsets_mapping=True,\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "\n",
    "    answer_start_indices = dataset[\"answer_start\"]\n",
    "    answer_texts = dataset[\"answer_text\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for index, offset in enumerate(offset_mapping):\n",
    "        start_char = answer_start_indices[index]\n",
    "        end_char = start_char + len(answer_texts[index])\n",
    "        sequence_ids = inputs.sequence_ids(index)\n",
    "\n",
    "        # Find the start and end token indices of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        idx = context_start\n",
    "        while idx <= context_end and offset[idx][0] <= start_char:\n",
    "            idx += 1\n",
    "        start_positions.append(idx - 1)\n",
    "\n",
    "        idx = context_end\n",
    "        while idx >= context_start and offset[idx][1] >= end_char:\n",
    "            idx -= 1\n",
    "        end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b72cf37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:26.949334800Z",
     "start_time": "2023-10-30T16:57:03.125194800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/67964 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d026b6e1de649ceb975c9a18ea6bea1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/14573 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa9d68d5081b46eeb0d785c298363d05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/14552 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0c589f9ee184737b01b3d8eecc19c67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = filtered_train_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_train_dataset.column_names,\n",
    ")\n",
    "tokenized_val_dataset = filtered_val_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_val_dataset.column_names,\n",
    ")\n",
    "tokenized_test_dataset = filtered_test_dataset.map(\n",
    "    preprocess_dataset,\n",
    "    batched=True,\n",
    "    remove_columns=filtered_test_dataset.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fc093e38a8b9eb4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:37.472560500Z",
     "start_time": "2023-10-30T16:57:26.950336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokenized train dataset entries have 384 tokens:  True\n",
      "All tokenized val dataset entries have 384 tokens:  True\n",
      "All tokenized test dataset entries have 384 tokens:  True\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"All tokenized train dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_train_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    f\"All tokenized val dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_val_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "print(\n",
    "    f\"All tokenized test dataset entries have {max_length} tokens: \",\n",
    "    all(\n",
    "        [\n",
    "            len(input_ids) == max_length\n",
    "            for input_ids in tokenized_test_dataset[\"input_ids\"]\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "training_number = 1\n",
    "\n",
    "model_name = \"squad-bert-uncased\"\n",
    "full_model_name = f\"{model_name}-{training_number}\"\n",
    "\n",
    "# Checkpoints\n",
    "checkpoint_filename_template = constants.checkpoint_filename_template\n",
    "checkpoints_path = (\n",
    "    extractive_qa_paths.training_checkpoints_dir\n",
    "    / full_model_name\n",
    "    / checkpoint_filename_template\n",
    ")\n",
    "\n",
    "# Hub\n",
    "hub_path = extractive_qa_paths.hub_models_location / full_model_name\n",
    "\n",
    "# Saved models\n",
    "saved_models_path = extractive_qa_paths.saved_models_dir / full_model_name\n",
    "\n",
    "# Figures\n",
    "figures_dir = extractive_qa_paths.figures_dir / full_model_name\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 8\n",
    "train_epochs = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:37.485628Z",
     "start_time": "2023-10-30T16:57:37.474562Z"
    }
   },
   "id": "72e1f89c3dcff7b"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d5bedb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:39.968658400Z",
     "start_time": "2023-10-30T16:57:37.487627800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForQuestionAnswering were not initialized from the PyTorch model and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load model for fine-tuning\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a9266b102c3f216",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:40.175069100Z",
     "start_time": "2023-10-30T16:57:39.942660400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset preparation\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
    "\n",
    "tf_train_dataset = core_qa_utils.convert_to_tf_dataset(\n",
    "    hf_dataset=tokenized_train_dataset,\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"start_positions\", \"end_positions\"],\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "tf_val_dataset = core_qa_utils.convert_to_tf_dataset(\n",
    "    hf_dataset=tokenized_val_dataset,\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"start_positions\", \"end_positions\"],\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "tf_test_dataset = core_qa_utils.convert_to_tf_dataset(\n",
    "    hf_dataset=tokenized_test_dataset,\n",
    "    columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\"],\n",
    "    label_cols=[\"start_positions\", \"end_positions\"],\n",
    "    collator=data_collator,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c73e96cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:40.191069200Z",
     "start_time": "2023-10-30T16:57:40.177071300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Login to hugging face hub in order to store the model there\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a10641c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:40.216080600Z",
     "start_time": "2023-10-30T16:57:40.191069200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoints_path, verbose=1, save_weights_only=True\n",
    ")\n",
    "early_stop_cb = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "# push_to_hub = keras_callbacks.PushToHubCallback(\n",
    "#     output_dir=full_model_name, tokenizer=tokenizer\n",
    "# )\n",
    "\n",
    "callbacks = [\n",
    "    checkpoint_cb, \n",
    "    early_stop_cb, \n",
    "    # push_to_hub\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4ec7915adf3b24c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:40.223080500Z",
     "start_time": "2023-10-30T16:57:40.208081400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3070 Ti, compute capability 8.6\n"
     ]
    }
   ],
   "source": [
    "# Compile\n",
    "num_train_steps = len(tf_train_dataset) * train_epochs\n",
    "\n",
    "lr_scheduler = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=2e-5, end_learning_rate=0.0, decay_steps=num_train_steps\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_scheduler)\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# Compile\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [\"accuracy\"]\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46ed3bc04bffb6bd",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:57:40.278080100Z",
     "start_time": "2023-10-30T16:57:40.224080200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_for_question_answering\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  108891648 \n",
      "                                                                 \n",
      " qa_outputs (Dense)          multiple                  1538      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 108,893,186\n",
      "Trainable params: 108,893,186\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "943d016bd9af345c",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:58:02.542718600Z",
     "start_time": "2023-10-30T16:57:40.257080200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'tf_bert_for_question_answering/bert/encoder/layer_._9/intermediate/Gelu/mul_1' defined at (most recent call last):\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Karol\\AppData\\Local\\Temp\\ipykernel_4392\\234921204.py\", line 2, in <module>\n      history = model.fit(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1638, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1833, in run_call_with_unpacked_inputs\n      from .modelcard import TrainingSummary  # tests_ignore\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1852, in call\n      outputs = self.bert(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1833, in run_call_with_unpacked_inputs\n      from .modelcard import TrainingSummary  # tests_ignore\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 862, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 548, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 554, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 510, in call\n      intermediate_output = self.intermediate(hidden_states=attention_output)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 414, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\activations.py\", line 359, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tf_bert_for_question_answering/bert/encoder/layer_._9/intermediate/Gelu/mul_1'\nfailed to allocate memory\n\t [[{{node tf_bert_for_question_answering/bert/encoder/layer_._9/intermediate/Gelu/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_24626]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Fit the model on the new data\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtf_train_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf_val_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\question_answering\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[0;32m     55\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mResourceExhaustedError\u001B[0m: Graph execution error:\n\nDetected at node 'tf_bert_for_question_answering/bert/encoder/layer_._9/intermediate/Gelu/mul_1' defined at (most recent call last):\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n      app.start()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n      await result\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Karol\\AppData\\Local\\Temp\\ipykernel_4392\\234921204.py\", line 2, in <module>\n      history = model.fit(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1638, in train_step\n      y_pred = self(x, training=True)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\training.py\", line 557, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1833, in run_call_with_unpacked_inputs\n      from .modelcard import TrainingSummary  # tests_ignore\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 1852, in call\n      outputs = self.bert(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 1833, in run_call_with_unpacked_inputs\n      from .modelcard import TrainingSummary  # tests_ignore\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 862, in call\n      encoder_outputs = self.encoder(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 548, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 554, in call\n      layer_outputs = layer_module(\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 510, in call\n      intermediate_output = self.intermediate(hidden_states=attention_output)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1097, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\transformers\\models\\bert\\modeling_tf_bert.py\", line 414, in call\n      hidden_states = self.intermediate_act_fn(hidden_states)\n    File \"C:\\Users\\Karol\\miniconda3\\envs\\question_answering\\lib\\site-packages\\keras\\activations.py\", line 359, in gelu\n      return tf.nn.gelu(x, approximate)\nNode: 'tf_bert_for_question_answering/bert/encoder/layer_._9/intermediate/Gelu/mul_1'\nfailed to allocate memory\n\t [[{{node tf_bert_for_question_answering/bert/encoder/layer_._9/intermediate/Gelu/mul_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_24626]"
     ]
    }
   ],
   "source": [
    "# Fit the model on the new data\n",
    "history = model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_val_dataset,\n",
    "    epochs=train_epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get best version of the model\n",
    "best_model = core_qa_utils.get_best_model_from_checkpoints(\n",
    "    model, history, model_name=full_model_name\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T16:48:06.639280Z"
    }
   },
   "id": "72a57f5bd9b9438f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save best model's weights\n",
    "extractive_qa_utils.save_model(best_model, model_name=full_model_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T16:48:06.641280600Z"
    }
   },
   "id": "f9673d7d1c09aece"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load best model\n",
    "loaded_best_model = extractive_qa_utils.load_weights_into_model(\n",
    "    best_model, model_name=full_model_name\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T16:48:06.644323900Z"
    }
   },
   "id": "814c2fb7f961d268"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get predictions from best_model\n",
    "best_model_preds = best_model.evaluate(tf_test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T16:48:06.646324500Z"
    }
   },
   "id": "5fcf4fbd43971926"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_best_model_preds = loaded_best_model.evaluate(tf_test_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-30T16:48:06.652581400Z",
     "start_time": "2023-10-30T16:48:06.648323500Z"
    }
   },
   "id": "5158f184f24da9bb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T16:48:06.650323600Z"
    }
   },
   "id": "48a8c08d0e3f253a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_best_model_preds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-30T16:48:06.651323Z"
    }
   },
   "id": "7f3cdb076ee266cc"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb87e32a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fa275afae44db8891397780aa08e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)lve/main/config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Artur\\.conda\\envs\\nlp_gpu\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Artur\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af5538288e84d759cd5d90bee2c853d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tf_model.h5:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForQuestionAnswering.\n",
      "\n",
      "All the layers of TFBertForQuestionAnswering were initialized from the model checkpoint at nlp-polish/squad-bert-1.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForQuestionAnswering for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6ae85fac964a028cdea6a60ceebb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fcab4d5e0eb4206a6d97f5195ca20ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d0e186abae4742b5fc2550caade65a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)/main/tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d672ce5b66a479d9d34fafa6317019e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.984375,\n",
       " 'start': 78,\n",
       " 'end': 105,\n",
       " 'answer': 'Jax, PyTorch and TensorFlow'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "question_answerer = pipeline(\"question-answering\", model=\"nlp-polish/squad-bert-1\")\n",
    "\n",
    "context = \"\"\"\n",
    "ðŸ¤— Transformers is backed by the three most popular deep learning libraries â€” Jax, PyTorch and TensorFlow â€” with a seamless integration\n",
    "between them. It's straightforward to train your models with one before loading them for inference with the other.\n",
    "\"\"\"\n",
    "question = \"Which deep learning libraries back ðŸ¤— Transformers?\"\n",
    "question_answerer(question=question, context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc068cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"accuracy\", \"val_accuracy\"],\n",
    "    title=\"Model accuracy\",\n",
    "    y_label=\"Accuracy\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{training_name}_accuracy.png\",\n",
    ")\n",
    "\n",
    "model_utils.plot_and_save_fig_from_history(\n",
    "    history,\n",
    "    attributes=[\"loss\", \"val_loss\"],\n",
    "    title=\"Model loss\",\n",
    "    y_label=\"Loss\",\n",
    "    x_label=\"Epoch\",\n",
    "    legend_descriptors=[\"Train\", \"Val\"],\n",
    "    figure_dir_path=figures_dir,\n",
    "    figure_filename=f\"{training_name}_loss.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d903b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = model_utils.get_best_model_from_checkpoints(\n",
    "    model,\n",
    "    history,\n",
    "    checkpoints_dir=checkpoints_dir,\n",
    "    checkpoint_filename_template=checkpoint_filename_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bb2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.save_model(\n",
    "    best_model,\n",
    "    model_name=model_name,\n",
    "    training_number=training_number,\n",
    "    saved_models_dir=constants.SAVED_MODEL_LOCATION,\n",
    "    default_model_version=constants.DEFAULT_MODEL_VERSION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "best_model.evaluate(tf_test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904d25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_preds = model_utils.get_class_preds(model, tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86334f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1 = model_utils.get_classification_evaluation_metrics(\n",
    "    class_actual=tokenized_test_dataset[\"emotions\"],\n",
    "    class_preds=class_preds,\n",
    "    average=\"micro\",\n",
    ")\n",
    "\n",
    "print(f\"Precision score: \", precision)\n",
    "print(f\"Recall score: \", recall)\n",
    "print(f\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc17f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.print_incorrectly_predicted_texts(\n",
    "    texts=raw_dataset[\"text_pl\"],\n",
    "    class_actual=raw_dataset[\"emotions\"],\n",
    "    class_preds=class_preds,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "question_answering",
   "language": "python",
   "display_name": "question_answering"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
